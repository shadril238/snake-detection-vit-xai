{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Author : shadril238\n",
        "!find /content -maxdepth 3 -iname \"sympy.py\" -o -iname \"sympy\""
      ],
      "metadata": {
        "id": "DZWPJcEdW_IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q uninstall -y sympy\n",
        "!pip -q install -U sympy==1.13.1\n",
        "\n",
        "import sympy\n",
        "print(\"sympy version:\", sympy.__version__)"
      ],
      "metadata": {
        "id": "eoHliNEYXEPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzBEKcwzCH80"
      },
      "outputs": [],
      "source": [
        "# Imports and configs\n",
        "\n",
        "import os, random, math, time, json\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "from torchvision import datasets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, accuracy_score,\n",
        "    f1_score, balanced_accuracy_score\n",
        ")\n",
        "\n",
        "import timm\n",
        "from timm.data import resolve_data_config, create_transform\n",
        "from timm.utils import ModelEmaV2\n",
        "\n",
        "!pip install optuna captum\n",
        "import optuna\n",
        "from captum.attr import LayerGradCam, IntegratedGradients\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "@dataclass\n",
        "class CFG:\n",
        "    dataset_path: str = \"/content/drive/MyDrive/ml-project2/dataset\"\n",
        "    num_workers: int = 2\n",
        "\n",
        "    train_ratio: float = 0.70\n",
        "    val_ratio: float = 0.15\n",
        "    test_ratio: float = 0.15\n",
        "\n",
        "    batch_size: int = 32\n",
        "    epochs_quick: int = 6\n",
        "    epochs_full: int = 14\n",
        "    patience: int = 5\n",
        "\n",
        "    lr: float = 3e-4\n",
        "    lr_head: float = 1e-3\n",
        "    weight_decay: float = 1e-4\n",
        "    label_smoothing: float = 0.05\n",
        "\n",
        "    img_size: int = 224\n",
        "    img_size_big: int = 384\n",
        "\n",
        "    mixup: float = 0.2\n",
        "    cutmix: float = 0.2\n",
        "\n",
        "    grad_clip: float = 1.0\n",
        "\n",
        "    n_trials_best_model: int = 12\n",
        "    n_trials_custom_vit: int = 15\n",
        "\n",
        "CFG = CFG()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKOcovKJC6T5"
      },
      "outputs": [],
      "source": [
        "# Mounts Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "assert os.path.exists(CFG.dataset_path), f\"Dataset path not found: {CFG.dataset_path}\"\n",
        "print(\"Dataset path OK:\", CFG.dataset_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12BuhcOdDKVN"
      },
      "outputs": [],
      "source": [
        "# Data Analysis\n",
        "\n",
        "img_exts = (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".gif\", \".webp\")\n",
        "\n",
        "def scan_dataset(root: str) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    for cls in sorted(os.listdir(root)):\n",
        "        cls_dir = os.path.join(root, cls)\n",
        "        if not os.path.isdir(cls_dir):\n",
        "            continue\n",
        "        files = [f for f in os.listdir(cls_dir) if f.lower().endswith(img_exts)]\n",
        "        rows.append({\"class\": cls, \"count\": len(files)})\n",
        "    return pd.DataFrame(rows).sort_values(\"count\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "df_stats = scan_dataset(CFG.dataset_path)\n",
        "display(df_stats)\n",
        "print(\"Total images:\", int(df_stats[\"count\"].sum()))\n",
        "print(\"Num classes:\", len(df_stats))\n",
        "\n",
        "plt.figure(figsize=(12, max(6, len(df_stats)*0.25)))\n",
        "plt.barh(df_stats[\"class\"], df_stats[\"count\"])\n",
        "plt.gca().invert_yaxis()\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.xlabel(\"Images per class\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "def show_samples_per_class(root: str, df: pd.DataFrame, k: int = 24, cols: int = 6):\n",
        "    k = min(k, len(df))\n",
        "    rows = math.ceil(k / cols)\n",
        "    plt.figure(figsize=(cols*3, rows*3))\n",
        "    shown = 0\n",
        "    for i in range(k):\n",
        "        cls = df.loc[i, \"class\"]\n",
        "        cls_dir = os.path.join(root, cls)\n",
        "        files = [f for f in os.listdir(cls_dir) if f.lower().endswith(img_exts)]\n",
        "        if not files:\n",
        "            continue\n",
        "        p = os.path.join(cls_dir, random.choice(files))\n",
        "        img = cv2.imread(p)\n",
        "        if img is None:\n",
        "            continue\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        shown += 1\n",
        "        plt.subplot(rows, cols, shown)\n",
        "        plt.imshow(img)\n",
        "        plt.title(cls, fontsize=9)\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_samples_per_class(CFG.dataset_path, df_stats, k=24, cols=6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7n0c06yDQCc"
      },
      "outputs": [],
      "source": [
        "# Detect corrupted images and size outliers.\n",
        "\n",
        "def check_images(root: str, max_per_class: int = 3000) -> pd.DataFrame:\n",
        "    bad = []\n",
        "    sizes = []\n",
        "\n",
        "    for cls in sorted(os.listdir(root)):\n",
        "        cls_dir = os.path.join(root, cls)\n",
        "        if not os.path.isdir(cls_dir):\n",
        "            continue\n",
        "        files = [f for f in os.listdir(cls_dir) if f.lower().endswith(img_exts)]\n",
        "        files = files[:max_per_class]\n",
        "        for f in files:\n",
        "            p = os.path.join(cls_dir, f)\n",
        "            try:\n",
        "                img = Image.open(p).convert(\"RGB\")\n",
        "                w, h = img.size\n",
        "                sizes.append((w, h))\n",
        "            except Exception as e:\n",
        "                bad.append({\"class\": cls, \"file\": f, \"error\": str(e)})\n",
        "\n",
        "    df_bad = pd.DataFrame(bad)\n",
        "    print(\"Bad images found:\", len(df_bad))\n",
        "\n",
        "    if len(sizes) > 0:\n",
        "        sizes = np.array(sizes)\n",
        "        print(\"Width min, median, max:\", int(sizes[:,0].min()), int(np.median(sizes[:,0])), int(sizes[:,0].max()))\n",
        "        print(\"Height min, median, max:\", int(sizes[:,1].min()), int(np.median(sizes[:,1])), int(sizes[:,1].max()))\n",
        "\n",
        "        plt.figure(figsize=(6,5))\n",
        "        plt.scatter(sizes[:,0], sizes[:,1], s=6, alpha=0.25)\n",
        "        plt.title(\"Image size scatter (W vs H)\")\n",
        "        plt.xlabel(\"Width\")\n",
        "        plt.ylabel(\"Height\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return df_bad\n",
        "\n",
        "df_bad = check_images(CFG.dataset_path)\n",
        "if len(df_bad) > 0:\n",
        "    display(df_bad.head(30))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tM6YCVUJDSCs"
      },
      "outputs": [],
      "source": [
        "# Creates stratified train/val/test splits\n",
        "\n",
        "base_ds = datasets.ImageFolder(CFG.dataset_path)\n",
        "classes = base_ds.classes\n",
        "num_classes = len(classes)\n",
        "targets = np.array([t for _, t in base_ds.samples])\n",
        "idx_all = np.arange(len(base_ds))\n",
        "\n",
        "train_idx, tmp_idx = train_test_split(\n",
        "    idx_all,\n",
        "    test_size=(1.0 - CFG.train_ratio),\n",
        "    stratify=targets,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "tmp_targets = targets[tmp_idx]\n",
        "val_rel = CFG.val_ratio / (CFG.val_ratio + CFG.test_ratio)\n",
        "\n",
        "val_idx, test_idx = train_test_split(\n",
        "    tmp_idx,\n",
        "    test_size=(1.0 - val_rel),\n",
        "    stratify=tmp_targets,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Split sizes:\", len(train_idx), len(val_idx), len(test_idx))\n",
        "print(\"Num classes:\", num_classes)\n",
        "\n",
        "def split_counts(idxs):\n",
        "    return np.bincount(targets[idxs], minlength=num_classes)\n",
        "\n",
        "df_split = pd.DataFrame({\n",
        "    \"class\": classes,\n",
        "    \"train\": split_counts(train_idx),\n",
        "    \"val\": split_counts(val_idx),\n",
        "    \"test\": split_counts(test_idx),\n",
        "})\n",
        "display(df_split.sort_values(\"train\", ascending=False).head(20))\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(df_split[\"train\"].values, label=\"train\")\n",
        "plt.plot(df_split[\"val\"].values, label=\"val\")\n",
        "plt.plot(df_split[\"test\"].values, label=\"test\")\n",
        "plt.title(\"Per-class counts across splits (class order = ImageFolder classes)\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.2)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXgY3FiJEYU-"
      },
      "outputs": [],
      "source": [
        "# Builds model-specific transforms, previews augmentations and normalization.\n",
        "\n",
        "def build_transforms(model_name: str, img_size: int, is_train: bool):\n",
        "    model = timm.create_model(model_name, pretrained=True)\n",
        "    data_cfg = resolve_data_config({}, model=model)\n",
        "    data_cfg[\"input_size\"] = (3, img_size, img_size)\n",
        "\n",
        "    if is_train:\n",
        "        tfm = create_transform(\n",
        "            input_size=data_cfg[\"input_size\"],\n",
        "            is_training=True,\n",
        "            interpolation=data_cfg.get(\"interpolation\", \"bicubic\"),\n",
        "            mean=data_cfg.get(\"mean\", (0.485, 0.456, 0.406)),\n",
        "            std=data_cfg.get(\"std\", (0.229, 0.224, 0.225)),\n",
        "            crop_pct=data_cfg.get(\"crop_pct\", 0.875),\n",
        "\n",
        "            auto_augment=\"rand-m7-mstd0.5-inc1\",\n",
        "            re_prob=0.10,\n",
        "            re_mode=\"pixel\",\n",
        "            re_count=1,\n",
        "        )\n",
        "    else:\n",
        "        tfm = create_transform(\n",
        "            input_size=data_cfg[\"input_size\"],\n",
        "            is_training=False,\n",
        "            interpolation=data_cfg.get(\"interpolation\", \"bicubic\"),\n",
        "            mean=data_cfg.get(\"mean\", (0.485, 0.456, 0.406)),\n",
        "            std=data_cfg.get(\"std\", (0.229, 0.224, 0.225)),\n",
        "            crop_pct=data_cfg.get(\"crop_pct\", 0.875),\n",
        "        )\n",
        "\n",
        "    return tfm, data_cfg\n",
        "\n",
        "def denorm_tensor(x, mean, std):\n",
        "    mean = torch.tensor(mean)[:, None, None]\n",
        "    std  = torch.tensor(std)[:, None, None]\n",
        "    x = x.cpu() * std + mean\n",
        "    return x.clamp(0, 1)\n",
        "\n",
        "preview_model = \"tf_efficientnetv2_s\"\n",
        "train_tfm, cfg_t = build_transforms(preview_model, CFG.img_size, True)\n",
        "\n",
        "preview_ds = datasets.ImageFolder(CFG.dataset_path, transform=train_tfm)\n",
        "x, y = preview_ds[random.randint(0, len(preview_ds)-1)]\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.imshow(denorm_tensor(x, cfg_t[\"mean\"], cfg_t[\"std\"]).permute(1,2,0))\n",
        "plt.title(f\"Augmented sample | class: {classes[y]}\")\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsRmDdiZEcWd"
      },
      "outputs": [],
      "source": [
        "# Creates dataLoaders\n",
        "\n",
        "def make_loaders(model_name: str, img_size: int, batch_size: int):\n",
        "    train_tfm, data_cfg = build_transforms(model_name, img_size, True)\n",
        "    eval_tfm, _ = build_transforms(model_name, img_size, False)\n",
        "\n",
        "    train_ds = datasets.ImageFolder(CFG.dataset_path, transform=train_tfm)\n",
        "    val_ds   = datasets.ImageFolder(CFG.dataset_path, transform=eval_tfm)\n",
        "    test_ds  = datasets.ImageFolder(CFG.dataset_path, transform=eval_tfm)\n",
        "\n",
        "    train_subset = Subset(train_ds, train_idx)\n",
        "    val_subset   = Subset(val_ds, val_idx)\n",
        "    test_subset  = Subset(test_ds, test_idx)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_subset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=CFG.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=CFG.num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_subset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=CFG.num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader, data_cfg, train_subset, val_subset, test_subset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KS2guJWvEeVm"
      },
      "outputs": [],
      "source": [
        "# Defines class-weighting, evaluation metrics, and EMA training loop.\n",
        "\n",
        "def make_class_weight_tensor():\n",
        "    class_counts = np.bincount(targets[train_idx], minlength=num_classes).astype(np.float32)\n",
        "    w = (class_counts.sum() / np.maximum(class_counts, 1.0))\n",
        "    w = w / w.mean()\n",
        "    return torch.tensor(w, device=device)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_y, all_p = [], []\n",
        "    n = 0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with autocast(device_type=\"cuda\" if device==\"cuda\" else \"cpu\"):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        preds = logits.argmax(1)\n",
        "\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(preds.detach().cpu().numpy())\n",
        "        n += x.size(0)\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    y_pred = np.concatenate(all_p)\n",
        "\n",
        "    return {\n",
        "        \"loss\": total_loss / max(1, n),\n",
        "        \"acc\": accuracy_score(y_true, y_pred),\n",
        "        \"bal_acc\": balanced_accuracy_score(y_true, y_pred),\n",
        "        \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\"),\n",
        "    }, y_true, y_pred\n",
        "\n",
        "def plot_history(hist, title):\n",
        "    df = pd.DataFrame(hist)\n",
        "    plt.figure(figsize=(12,4))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(df[\"train_loss\"], label=\"train_loss\")\n",
        "    plt.plot(df[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.title(title + \" loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.2)\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(df[\"train_acc\"], label=\"train_acc\")\n",
        "    plt.plot(df[\"val_acc\"], label=\"val_acc\")\n",
        "    plt.title(title + \" accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.2)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    epochs: int,\n",
        "    lr: float,\n",
        "    weight_decay: float,\n",
        "    patience: int,\n",
        "    model_name: str\n",
        "):\n",
        "    model = model.to(device)\n",
        "    scaler = GradScaler(\"cuda\") if device == \"cuda\" else GradScaler(\"cpu\")\n",
        "    ema = ModelEmaV2(model, decay=0.999)\n",
        "\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=max(1, epochs))\n",
        "\n",
        "    best = -1.0\n",
        "    best_state = None\n",
        "    bad = 0\n",
        "    hist = []\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        tot, cor, tloss = 0, 0, 0.0\n",
        "\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "\n",
        "            with autocast(device_type=\"cuda\" if device==\"cuda\" else \"cpu\"):\n",
        "                logits = model(x)\n",
        "                loss = criterion(logits, y)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(opt)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.grad_clip)\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "\n",
        "            ema.update(model)\n",
        "\n",
        "            tloss += loss.item() * x.size(0)\n",
        "            cor += (logits.argmax(1) == y).sum().item()\n",
        "            tot += x.size(0)\n",
        "\n",
        "        sch.step()\n",
        "\n",
        "        val_m, _, _ = evaluate(ema.module, val_loader, criterion)\n",
        "\n",
        "        tr_acc = cor / max(1, tot)\n",
        "        tr_loss = tloss / max(1, tot)\n",
        "\n",
        "        hist.append({\n",
        "            \"epoch\": ep,\n",
        "            \"train_loss\": tr_loss,\n",
        "            \"train_acc\": tr_acc,\n",
        "            \"val_loss\": val_m[\"loss\"],\n",
        "            \"val_acc\": val_m[\"acc\"],\n",
        "            \"val_f1_macro\": val_m[\"f1_macro\"],\n",
        "            \"lr\": opt.param_groups[0][\"lr\"]\n",
        "        })\n",
        "\n",
        "        print(f\"[{model_name}] ep {ep:02d} tr_acc {tr_acc:.4f} val_acc {val_m['acc']:.4f} val_f1 {val_m['f1_macro']:.4f}\")\n",
        "\n",
        "        if val_m[\"acc\"] > best:\n",
        "            best = val_m[\"acc\"]\n",
        "            best_state = {k: v.detach().cpu() for k, v in ema.module.state_dict().items()}\n",
        "            bad = 0\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= patience:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "\n",
        "    if best_state is not None:\n",
        "        ema.module.load_state_dict(best_state)\n",
        "\n",
        "    return ema.module, hist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDe1Z6f5EjdW"
      },
      "outputs": [],
      "source": [
        "# Extracts pretrained CNN embeddings for train, val, test splits.\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_embeddings(backbone_name: str, img_size: int, batch_size: int):\n",
        "    eval_tfm, cfg = build_transforms(backbone_name, img_size, False)\n",
        "    ds = datasets.ImageFolder(CFG.dataset_path, transform=eval_tfm)\n",
        "\n",
        "    tr = Subset(ds, train_idx)\n",
        "    va = Subset(ds, val_idx)\n",
        "    te = Subset(ds, test_idx)\n",
        "\n",
        "    tr_loader = DataLoader(tr, batch_size=batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "    va_loader = DataLoader(va, batch_size=batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "    te_loader = DataLoader(te, batch_size=batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "\n",
        "    feat_model = timm.create_model(backbone_name, pretrained=True, num_classes=0).to(device).eval()\n",
        "    dim = feat_model.num_features\n",
        "    print(\"Backbone:\", backbone_name, \"| feature_dim:\", dim)\n",
        "\n",
        "    def run(loader):\n",
        "        feats, labs = [], []\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            with autocast(device_type=\"cuda\" if device==\"cuda\" else \"cpu\"):\n",
        "                f = feat_model(x)\n",
        "            feats.append(f.detach().cpu().float().numpy())\n",
        "            labs.append(y.numpy())\n",
        "        return np.concatenate(feats), np.concatenate(labs)\n",
        "\n",
        "    Xtr, ytr = run(tr_loader)\n",
        "    Xva, yva = run(va_loader)\n",
        "    Xte, yte = run(te_loader)\n",
        "\n",
        "    return (Xtr, ytr), (Xva, yva), (Xte, yte), cfg\n",
        "\n",
        "cnn_backbone = \"tf_efficientnetv2_s\"\n",
        "(Xtr_cnn, ytr), (Xva_cnn, yva), (Xte_cnn, yte), cfg_cnn = extract_embeddings(cnn_backbone, CFG.img_size, batch_size=64)\n",
        "\n",
        "print(\"CNN embeddings:\", Xtr_cnn.shape, Xva_cnn.shape, Xte_cnn.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6635ApEQEl2P"
      },
      "outputs": [],
      "source": [
        "# Extracts ViT embeddings and concatenates with CNN for hybrid features.\n",
        "\n",
        "vit_backbone = \"vit_base_patch16_224\"\n",
        "(Xtr_vit, _), (Xva_vit, _), (Xte_vit, _), cfg_vit = extract_embeddings(vit_backbone, CFG.img_size, batch_size=64)\n",
        "\n",
        "print(\"ViT embeddings:\", Xtr_vit.shape, Xva_vit.shape, Xte_vit.shape)\n",
        "\n",
        "Xtr_h = np.concatenate([Xtr_cnn, Xtr_vit], axis=1)\n",
        "Xva_h = np.concatenate([Xva_cnn, Xva_vit], axis=1)\n",
        "Xte_h = np.concatenate([Xte_cnn, Xte_vit], axis=1)\n",
        "\n",
        "print(\"Hybrid embeddings:\", Xtr_h.shape, Xva_h.shape, Xte_h.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "565G5vn5Eou-"
      },
      "outputs": [],
      "source": [
        "# Visualizes CNN and hybrid embeddings using t-SNE plots.\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def tsne_plot(X, y, title, max_points=2000):\n",
        "    n = min(max_points, len(X))\n",
        "    idx = np.random.choice(len(X), size=n, replace=False)\n",
        "    Xs = StandardScaler().fit_transform(X[idx])\n",
        "\n",
        "    tsne = TSNE(n_components=2, perplexity=30, init=\"pca\", learning_rate=\"auto\", random_state=42)\n",
        "    Z = tsne.fit_transform(Xs)\n",
        "\n",
        "    plt.figure(figsize=(7,6))\n",
        "    plt.scatter(Z[:,0], Z[:,1], c=y[idx], s=6, alpha=0.6)\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "tsne_plot(Xtr_cnn, ytr, \"t-SNE: CNN embeddings (train subset)\")\n",
        "tsne_plot(Xtr_h, ytr, \"t-SNE: Hybrid embeddings (CNN + ViT) (train subset)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcbVMJFqErHO"
      },
      "outputs": [],
      "source": [
        "# Trains MLP classifier on extracted CNN embeddings.\n",
        "\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, in_dim: int, num_classes: int, hidden: int = 512, dropout: float = 0.3):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden),\n",
        "            nn.BatchNorm1d(hidden),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden, hidden//2),\n",
        "            nn.BatchNorm1d(hidden//2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden//2, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class NumpyFeatureDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    def __getitem__(self, i):\n",
        "        return self.X[i], self.y[i]\n",
        "\n",
        "def train_mlp_on_features(Xtr, ytr, Xva, yva, Xte, yte, hidden=512, dropout=0.3, lr=1e-3, wd=1e-4, epochs=25, patience=6, name=\"MLP\"):\n",
        "    tr_ds = NumpyFeatureDataset(Xtr, ytr)\n",
        "    va_ds = NumpyFeatureDataset(Xva, yva)\n",
        "    te_ds = NumpyFeatureDataset(Xte, yte)\n",
        "\n",
        "    tr_loader = DataLoader(tr_ds, batch_size=256, shuffle=True, drop_last=True)\n",
        "    va_loader = DataLoader(va_ds, batch_size=256, shuffle=False)\n",
        "    te_loader = DataLoader(te_ds, batch_size=256, shuffle=False)\n",
        "\n",
        "    model = MLPClassifier(Xtr.shape[1], num_classes, hidden=hidden, dropout=dropout).to(device)\n",
        "\n",
        "    # class weighted loss\n",
        "    class_counts = np.bincount(ytr, minlength=num_classes).astype(np.float32)\n",
        "    w = (class_counts.sum() / np.maximum(class_counts, 1.0))\n",
        "    w = w / w.mean()\n",
        "    w = torch.tensor(w, device=device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(weight=w, label_smoothing=0.0)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "\n",
        "    best = -1.0\n",
        "    best_state = None\n",
        "    bad = 0\n",
        "    hist = []\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        tloss, cor, tot = 0.0, 0, 0\n",
        "        for xb, yb in tr_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            tloss += loss.item() * xb.size(0)\n",
        "            cor += (logits.argmax(1) == yb).sum().item()\n",
        "            tot += xb.size(0)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            vloss, vcor, vtot = 0.0, 0, 0\n",
        "            for xb, yb in va_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                logits = model(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "                vloss += loss.item() * xb.size(0)\n",
        "                vcor += (logits.argmax(1) == yb).sum().item()\n",
        "                vtot += xb.size(0)\n",
        "\n",
        "        tr_acc = cor / max(1, tot)\n",
        "        va_acc = vcor / max(1, vtot)\n",
        "        hist.append({\"epoch\": ep, \"train_loss\": tloss/max(1,tot), \"train_acc\": tr_acc, \"val_loss\": vloss/max(1,vtot), \"val_acc\": va_acc})\n",
        "\n",
        "        print(f\"[{name}] ep {ep:02d} tr_acc {tr_acc:.4f} val_acc {va_acc:.4f}\")\n",
        "\n",
        "        if va_acc > best:\n",
        "            best = va_acc\n",
        "            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
        "            bad = 0\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= patience:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "\n",
        "    model.eval()\n",
        "    all_p = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in te_loader:\n",
        "            xb = xb.to(device)\n",
        "            logits = model(xb)\n",
        "            all_p.append(logits.argmax(1).cpu().numpy())\n",
        "    y_pred = np.concatenate(all_p)\n",
        "\n",
        "    test_acc = accuracy_score(yte, y_pred)\n",
        "    test_f1  = f1_score(yte, y_pred, average=\"macro\")\n",
        "    return model, hist, {\"test_acc\": test_acc, \"test_f1_macro\": test_f1}\n",
        "\n",
        "mlp_cnn, hist_mlp_cnn, res_mlp_cnn = train_mlp_on_features(\n",
        "    Xtr_cnn, ytr, Xva_cnn, yva, Xte_cnn, yte,\n",
        "    hidden=512, dropout=0.35, lr=1e-3, wd=1e-4,\n",
        "    epochs=30, patience=6,\n",
        "    name=\"MLP_CNNfeat\"\n",
        ")\n",
        "\n",
        "plot_history(hist_mlp_cnn, \"MLP on CNN features\")\n",
        "print(\"MLP_CNNfeat:\", res_mlp_cnn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipDsJTwcEvKn"
      },
      "outputs": [],
      "source": [
        "# Fine-tunes end-to-end ViT baseline and evaluates performance.\n",
        "\n",
        "vit_model_name = \"vit_base_patch16_224\"\n",
        "train_loader, val_loader, test_loader, data_cfg, tr_sub, va_sub, te_sub = make_loaders(\n",
        "    vit_model_name, CFG.img_size, CFG.batch_size\n",
        ")\n",
        "\n",
        "w = make_class_weight_tensor()\n",
        "criterion = nn.CrossEntropyLoss(weight=w, label_smoothing=CFG.label_smoothing)\n",
        "\n",
        "vit_model = timm.create_model(vit_model_name, pretrained=True, num_classes=num_classes)\n",
        "\n",
        "vit_model, hist_vit = train_model(\n",
        "    vit_model, train_loader, val_loader,\n",
        "    criterion=criterion,\n",
        "    epochs=CFG.epochs_quick,\n",
        "    lr=CFG.lr,\n",
        "    weight_decay=CFG.weight_decay,\n",
        "    patience=CFG.patience,\n",
        "    model_name=\"ViT_end2end\"\n",
        ")\n",
        "\n",
        "plot_history(hist_vit, \"ViT end to end (quick)\")\n",
        "\n",
        "test_m_vit, y_true_vit, y_pred_vit = evaluate(vit_model, test_loader, criterion)\n",
        "print(\"ViT test:\", test_m_vit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKj-dDpWEtgv"
      },
      "outputs": [],
      "source": [
        "# Trains MLP on hybrid CNN+ViT concatenated features.\n",
        "\n",
        "mlp_hybrid, hist_mlp_hybrid, res_mlp_hybrid = train_mlp_on_features(\n",
        "    Xtr_h, ytr, Xva_h, yva, Xte_h, yte,\n",
        "    hidden=1024, dropout=0.35, lr=8e-4, wd=2e-4,\n",
        "    epochs=30, patience=6,\n",
        "    name=\"MLP_Hybridfeat\"\n",
        ")\n",
        "\n",
        "plot_history(hist_mlp_hybrid, \"MLP on Hybrid features (CNN + ViT)\")\n",
        "print(\"MLP_Hybridfeat:\", res_mlp_hybrid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXJ3wwZ0ExS_"
      },
      "outputs": [],
      "source": [
        "# Compares three models\n",
        "best_val_mlp_cnn = max([x[\"val_acc\"] for x in hist_mlp_cnn])\n",
        "best_val_mlp_hyb = max([x[\"val_acc\"] for x in hist_mlp_hybrid])\n",
        "best_val_vit     = max([x[\"val_acc\"] for x in hist_vit])\n",
        "\n",
        "df_cmp = pd.DataFrame([\n",
        "    {\"model_type\": \"DL_on_CNN_features\", \"best_val_acc\": best_val_mlp_cnn, \"test_acc\": res_mlp_cnn[\"test_acc\"]},\n",
        "    {\"model_type\": \"Hybrid_DL_on_CNNplusViT_features\", \"best_val_acc\": best_val_mlp_hyb, \"test_acc\": res_mlp_hybrid[\"test_acc\"]},\n",
        "    {\"model_type\": \"ViT_end2end\", \"best_val_acc\": best_val_vit, \"test_acc\": test_m_vit[\"acc\"]},\n",
        "]).sort_values(\"best_val_acc\", ascending=False)\n",
        "\n",
        "display(df_cmp)\n",
        "\n",
        "best_type = df_cmp.iloc[0][\"model_type\"]\n",
        "print(\"Best by validation:\", best_type)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sfd68QWlEyLA"
      },
      "outputs": [],
      "source": [
        "# Tunes best model hyperparameters using Optuna optimization trials.\n",
        "\n",
        "def objective_best_model(trial: optuna.Trial):\n",
        "    if best_type in [\"DL_on_CNN_features\", \"Hybrid_DL_on_CNNplusViT_features\"]:\n",
        "        Xtr = Xtr_cnn if best_type == \"DL_on_CNN_features\" else Xtr_h\n",
        "        Xva = Xva_cnn if best_type == \"DL_on_CNN_features\" else Xva_h\n",
        "        ytr0, yva0 = ytr, yva\n",
        "\n",
        "        hidden = trial.suggest_categorical(\"hidden\", [256, 512, 768, 1024, 1536])\n",
        "        dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
        "        lr = trial.suggest_float(\"lr\", 1e-4, 3e-3, log=True)\n",
        "        wd = trial.suggest_float(\"weight_decay\", 1e-6, 5e-3, log=True)\n",
        "\n",
        "        model, hist, _ = train_mlp_on_features(\n",
        "            Xtr, ytr0, Xva, yva0, Xva, yva0,\n",
        "            hidden=hidden, dropout=dropout, lr=lr, wd=wd,\n",
        "            epochs=18, patience=5,\n",
        "            name=\"tune_mlp\"\n",
        "        )\n",
        "        best_val = max([h[\"val_acc\"] for h in hist])\n",
        "        return best_val\n",
        "\n",
        "    else:\n",
        "        model_name = vit_model_name\n",
        "        lr = trial.suggest_float(\"lr\", 1e-5, 8e-4, log=True)\n",
        "        wd = trial.suggest_float(\"weight_decay\", 1e-6, 5e-3, log=True)\n",
        "        ls = trial.suggest_float(\"label_smoothing\", 0.0, 0.15)\n",
        "\n",
        "        bs = trial.suggest_categorical(\"batch_size\", [16, 32])\n",
        "        img_size = trial.suggest_categorical(\"img_size\", [224, 384])\n",
        "\n",
        "        train_loader, val_loader, _, _, _, _, _ = make_loaders(model_name, img_size, bs)\n",
        "\n",
        "        w = make_class_weight_tensor()\n",
        "        criterion = nn.CrossEntropyLoss(weight=w, label_smoothing=ls)\n",
        "\n",
        "        model = timm.create_model(model_name, pretrained=True, num_classes=num_classes)\n",
        "\n",
        "        model, hist = train_model(\n",
        "            model, train_loader, val_loader,\n",
        "            criterion=criterion,\n",
        "            epochs=6,\n",
        "            lr=lr,\n",
        "            weight_decay=wd,\n",
        "            patience=3,\n",
        "            model_name=\"tune_vit\"\n",
        "        )\n",
        "        best_val = max([h[\"Acc\"] for h in hist])\n",
        "        return best_val\n",
        "\n",
        "study_best = optuna.create_study(direction=\"maximize\")\n",
        "study_best.optimize(objective_best_model, n_trials=CFG.n_trials_best_model)\n",
        "\n",
        "print(\"Best tuned params for best model:\", study_best.best_params)\n",
        "print(\"Best acc:\", study_best.best_value)\n",
        "best_params = study_best.best_params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24f4s_qwE0xv"
      },
      "outputs": [],
      "source": [
        "# Retrains tuned best model fully\n",
        "\n",
        "final_results = {}\n",
        "\n",
        "if best_type in [\"DL_on_CNN_features\", \"Hybrid_DL_on_CNNplusViT_features\"]:\n",
        "    Xtr = Xtr_cnn if best_type == \"DL_on_CNN_features\" else Xtr_h\n",
        "    Xva = Xva_cnn if best_type == \"DL_on_CNN_features\" else Xva_h\n",
        "    Xte = Xte_cnn if best_type == \"DL_on_CNN_features\" else Xte_h\n",
        "\n",
        "    final_mlp, hist_final_mlp, res_final_mlp = train_mlp_on_features(\n",
        "        Xtr, ytr, Xva, yva, Xte, yte,\n",
        "        hidden=best_params[\"hidden\"],\n",
        "        dropout=best_params[\"dropout\"],\n",
        "        lr=best_params[\"lr\"],\n",
        "        wd=best_params[\"weight_decay\"],\n",
        "        epochs=35, patience=7,\n",
        "        name=\"FINAL_best_MLP\"\n",
        "    )\n",
        "    plot_history(hist_final_mlp, \"FINAL best MLP (tuned)\")\n",
        "    final_results[\"best_model_test_acc\"] = res_final_mlp[\"test_acc\"]\n",
        "    print(\"FINAL best MLP:\", res_final_mlp)\n",
        "\n",
        "else:\n",
        "    img_size = best_params[\"img_size\"]\n",
        "    bs = best_params[\"batch_size\"]\n",
        "    lr = best_params[\"lr\"]\n",
        "    wd = best_params[\"weight_decay\"]\n",
        "    ls = best_params[\"label_smoothing\"]\n",
        "\n",
        "    train_loader, val_loader, test_loader, data_cfg, _, _, _ = make_loaders(vit_model_name, img_size, bs)\n",
        "    w = make_class_weight_tensor()\n",
        "    criterion = nn.CrossEntropyLoss(weight=w, label_smoothing=ls)\n",
        "\n",
        "    vit_final = timm.create_model(vit_model_name, pretrained=True, num_classes=num_classes)\n",
        "    vit_final, hist_final_vit = train_model(\n",
        "        vit_final, train_loader, val_loader,\n",
        "        criterion=criterion,\n",
        "        epochs=CFG.epochs_full,\n",
        "        lr=lr,\n",
        "        weight_decay=wd,\n",
        "        patience=CFG.patience,\n",
        "        model_name=\"FINAL_best_ViT\"\n",
        "    )\n",
        "    plot_history(hist_final_vit, \"FINAL best ViT (tuned)\")\n",
        "\n",
        "    test_m, yt, yp = evaluate(vit_final, test_loader, criterion)\n",
        "    print(\"FINAL best ViT test:\", test_m)\n",
        "    final_results[\"best_model_test_acc\"] = test_m[\"acc\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMDE1AZIE2v4"
      },
      "outputs": [],
      "source": [
        "# Tunes CustomViT architecture and training hyperparameters via Optuna.\n",
        "\n",
        "import optuna\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "class CustomViT(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        backbone_name: str,\n",
        "        img_size: int,\n",
        "        num_classes: int,\n",
        "        head_hidden: int,\n",
        "        dropout: float,\n",
        "        unfreeze_blocks: int\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # make backbone match the input image size\n",
        "        # dynamic_img_size=True makes it tolerant in many timm ViT variants\n",
        "        self.backbone = timm.create_model(\n",
        "            backbone_name,\n",
        "            pretrained=True,\n",
        "            num_classes=0,\n",
        "            img_size=img_size,\n",
        "            dynamic_img_size=True\n",
        "        )\n",
        "        d = self.backbone.num_features\n",
        "\n",
        "        # freeze all\n",
        "        for p in self.backbone.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # unfreeze last N blocks (if available)\n",
        "        if hasattr(self.backbone, \"blocks\"):\n",
        "            n_blocks = len(self.backbone.blocks)\n",
        "            k = max(1, min(int(unfreeze_blocks), n_blocks))\n",
        "            for blk in self.backbone.blocks[-k:]:\n",
        "                for p in blk.parameters():\n",
        "                    p.requires_grad = True\n",
        "\n",
        "        # unfreeze norm (if available)\n",
        "        if hasattr(self.backbone, \"norm\"):\n",
        "            for p in self.backbone.norm.parameters():\n",
        "                p.requires_grad = True\n",
        "\n",
        "        # custom classifier head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(d, head_hidden),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(head_hidden, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = self.backbone(x)\n",
        "        return self.head(f)\n",
        "\n",
        "def objective_custom_vit(trial: optuna.Trial):\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 6e-4, log=True)\n",
        "    wd = trial.suggest_float(\"weight_decay\", 1e-6, 5e-3, log=True)\n",
        "    ls = trial.suggest_float(\"label_smoothing\", 0.0, 0.12)\n",
        "\n",
        "    head_hidden = trial.suggest_categorical(\"head_hidden\", [256, 512, 768, 1024])\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
        "    unfreeze_blocks = trial.suggest_int(\"unfreeze_blocks\", 2, 10)\n",
        "\n",
        "    img_size = trial.suggest_categorical(\"img_size\", [224, 384])\n",
        "    bs = trial.suggest_categorical(\"batch_size\", [16, 32])\n",
        "\n",
        "    backbone = vit_backbone  # e.g. \"vit_base_patch16_224\"\n",
        "\n",
        "    # loaders use your transforms with chosen img_size\n",
        "    train_loader, val_loader, _, _, _, _, _ = make_loaders(backbone, img_size, bs)\n",
        "\n",
        "    w = make_class_weight_tensor()\n",
        "    criterion = nn.CrossEntropyLoss(weight=w, label_smoothing=ls)\n",
        "\n",
        "    # IMPORTANT: pass img_size into CustomViT\n",
        "    model = CustomViT(\n",
        "        backbone_name=backbone,\n",
        "        img_size=img_size,\n",
        "        num_classes=num_classes,\n",
        "        head_hidden=head_hidden,\n",
        "        dropout=dropout,\n",
        "        unfreeze_blocks=unfreeze_blocks\n",
        "    )\n",
        "\n",
        "    model, hist = train_model(\n",
        "        model, train_loader, val_loader,\n",
        "        criterion=criterion,\n",
        "        epochs=7,\n",
        "        lr=lr,\n",
        "        weight_decay=wd,\n",
        "        patience=3,\n",
        "        model_name=\"tune_custom_vit\"\n",
        "    )\n",
        "    return max(h[\"val_acc\"] for h in hist)\n",
        "\n",
        "study_custom = optuna.create_study(direction=\"maximize\")\n",
        "study_custom.optimize(objective_custom_vit, n_trials=CFG.n_trials_custom_vit)\n",
        "\n",
        "print(\"Custom ViT best params:\", study_custom.best_params)\n",
        "print(\"Custom ViT best val acc:\", study_custom.best_value)\n",
        "\n",
        "custom_params = study_custom.best_params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIwbg1mYE424"
      },
      "outputs": [],
      "source": [
        "# Evaluate Matrics\n",
        "\n",
        "backbone = vit_backbone\n",
        "img_size = custom_params[\"img_size\"]\n",
        "bs = custom_params[\"batch_size\"]\n",
        "\n",
        "train_loader, val_loader, test_loader, data_cfg, _, _, _ = make_loaders(backbone, img_size, bs)\n",
        "\n",
        "w = make_class_weight_tensor()\n",
        "criterion = nn.CrossEntropyLoss(weight=w, label_smoothing=custom_params[\"label_smoothing\"])\n",
        "\n",
        "custom_vit_final = CustomViT(\n",
        "    backbone_name=backbone,\n",
        "    img_size=img_size,\n",
        "    num_classes=num_classes,\n",
        "    head_hidden=custom_params[\"head_hidden\"],\n",
        "    dropout=custom_params[\"dropout\"],\n",
        "    unfreeze_blocks=custom_params[\"unfreeze_blocks\"]\n",
        ")\n",
        "\n",
        "custom_vit_final, hist_custom_final = train_model(\n",
        "    custom_vit_final,\n",
        "    train_loader, val_loader,\n",
        "    criterion=criterion,\n",
        "    epochs=CFG.epochs_full,\n",
        "    lr=custom_params[\"lr\"],\n",
        "    weight_decay=custom_params[\"weight_decay\"],\n",
        "    patience=CFG.patience,\n",
        "    model_name=\"FINAL_CustomViT\"\n",
        ")\n",
        "\n",
        "plot_history(hist_custom_final, \"FINAL Custom ViT (tuned)\")\n",
        "\n",
        "train_m, y_true, y_pred = evaluate(custom_vit_final, train_loader, criterion)\n",
        "print(\"Custom ViT:\", train_m)\n",
        "print(classification_report(y_true, y_pred, target_names=classes, digits=4))\n",
        "\n",
        "@torch.no_grad()\n",
        "def tta_eval(model, loader):\n",
        "    model.eval()\n",
        "    all_y, all_p = [], []\n",
        "    for x, y in loader:\n",
        "        x = x.to(device)\n",
        "        with autocast(device_type=\"cuda\" if device==\"cuda\" else \"cpu\"):\n",
        "            logits1 = model(x)\n",
        "            logits2 = model(torch.flip(x, dims=[3]))\n",
        "            logits = (logits1 + logits2) / 2.0\n",
        "        preds = logits.argmax(1).cpu().numpy()\n",
        "        all_p.append(preds)\n",
        "        all_y.append(y.numpy())\n",
        "    y_true = np.concatenate(all_y)\n",
        "    y_pred = np.concatenate(all_p)\n",
        "    return accuracy_score(y_true, y_pred), f1_score(y_true, y_pred, average=\"macro\")\n",
        "\n",
        "tta_acc, tta_f1 = tta_eval(custom_vit_final, train_loader)\n",
        "print(\"Custom ViT Test acc:\", tta_acc)\n",
        "print(\"Custom ViT macro F1:\", tta_f1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names, title=\"Confusion Matrix\", normalize=False, max_classes_to_show=None):\n",
        "    cm = cm.astype(np.float32)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm / (cm.sum(axis=1, keepdims=True) + 1e-8)\n",
        "\n",
        "    if max_classes_to_show is not None and cm.shape[0] > max_classes_to_show:\n",
        "        cm = cm[:max_classes_to_show, :max_classes_to_show]\n",
        "        class_names = class_names[:max_classes_to_show]\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(cm, interpolation=\"nearest\")\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=90, fontsize=8)\n",
        "    plt.yticks(tick_marks, class_names, fontsize=8)\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_preds(model, loader):\n",
        "    model.eval()\n",
        "    all_y, all_p = [], []\n",
        "    for x, y in loader:\n",
        "        x = x.to(device)\n",
        "        with autocast(device_type=\"cuda\" if device==\"cuda\" else \"cpu\"):\n",
        "            logits = model(x)\n",
        "        preds = logits.argmax(1).cpu().numpy()\n",
        "        all_p.append(preds)\n",
        "        all_y.append(y.numpy())\n",
        "    y_true = np.concatenate(all_y)\n",
        "    y_pred = np.concatenate(all_p)\n",
        "    return y_true, y_pred\n",
        "\n",
        "@torch.no_grad()\n",
        "def tta_eval_preds(model, loader):\n",
        "    model.eval()\n",
        "    all_y, all_p = [], []\n",
        "    for x, y in loader:\n",
        "        x = x.to(device)\n",
        "        with autocast(device_type=\"cuda\" if device==\"cuda\" else \"cpu\"):\n",
        "            logits1 = model(x)\n",
        "            logits2 = model(torch.flip(x, dims=[3]))\n",
        "            logits = (logits1 + logits2) / 2.0\n",
        "        preds = logits.argmax(1).cpu().numpy()\n",
        "        all_p.append(preds)\n",
        "        all_y.append(y.numpy())\n",
        "    y_true = np.concatenate(all_y)\n",
        "    y_pred = np.concatenate(all_p)\n",
        "    return y_true, y_pred\n",
        "\n",
        "ytr_true, ytr_pred = get_preds(custom_vit_final, train_loader)\n",
        "cm_train = confusion_matrix(ytr_true, ytr_pred, labels=list(range(num_classes)))\n",
        "plot_confusion_matrix(cm_train, classes, title=\"Confusion Matrix\", normalize=False)\n",
        "plot_confusion_matrix(cm_train, classes, title=\"Confusion Matrix (normalized)\", normalize=True)\n",
        "\n",
        "print(\"Confusion matrices generated\")\n"
      ],
      "metadata": {
        "id": "7wAvHslzIE2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vltga9pYE6hz"
      },
      "outputs": [],
      "source": [
        "# Generates Integrated Gradients heatmaps to explain CustomViT predictions.\n",
        "\n",
        "custom_vit_final.eval()\n",
        "ig = IntegratedGradients(custom_vit_final)\n",
        "\n",
        "samples_to_show = 4\n",
        "idxs = np.random.choice(range(len(test_loader.dataset)), size=min(samples_to_show, len(test_loader.dataset)), replace=False)\n",
        "\n",
        "plt.figure(figsize=(12, 3*samples_to_show))\n",
        "\n",
        "for i, idx in enumerate(idxs, start=1):\n",
        "    x, y = test_loader.dataset[idx]\n",
        "    x_in = x.unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = custom_vit_final(x_in).argmax(1).item()\n",
        "\n",
        "    attr = ig.attribute(x_in, target=pred, n_steps=16)\n",
        "    attr = attr.abs().mean(dim=1).squeeze().detach().cpu().numpy()\n",
        "    attr = (attr - attr.min()) / (attr.max() - attr.min() + 1e-8)\n",
        "\n",
        "    img = denorm_tensor(x, data_cfg[\"mean\"], data_cfg[\"std\"]).permute(1,2,0).numpy()\n",
        "    heat = cv2.applyColorMap((attr*255).astype(np.uint8), cv2.COLORMAP_JET)\n",
        "    heat = cv2.cvtColor(heat, cv2.COLOR_BGR2RGB) / 255.0\n",
        "    overlay = (0.55*img + 0.45*heat).clip(0,1)\n",
        "\n",
        "    plt.subplot(samples_to_show, 3, (i-1)*3 + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Raw | True: {classes[y]}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(samples_to_show, 3, (i-1)*3 + 2)\n",
        "    plt.imshow(attr, cmap=\"jet\")\n",
        "    plt.title(\"IG heatmap\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(samples_to_show, 3, (i-1)*3 + 3)\n",
        "    plt.imshow(overlay)\n",
        "    plt.title(f\"Overlay | Pred: {classes[pred]}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XAI (LIME Setup)\n",
        "\n",
        "!pip -q install lime scikit-image\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import slic, mark_boundaries\n",
        "from PIL import Image\n",
        "\n",
        "lime_eval_tfm, _ = build_transforms(backbone, img_size, is_train=False)\n",
        "\n",
        "def get_raw_test_sample(i: int):\n",
        "    subset = test_loader.dataset\n",
        "    img_path, y = subset.dataset.samples[subset.indices[i]]\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    img_np = np.array(img, dtype=np.uint8)\n",
        "    return img_np, int(y), img_path\n",
        "\n",
        "@torch.no_grad()\n",
        "def lime_predict_proba(images: List[np.ndarray]) -> np.ndarray:\n",
        "    batch = []\n",
        "    for img_np in images:\n",
        "        pil = Image.fromarray(img_np.astype(np.uint8))\n",
        "        x = lime_eval_tfm(pil)\n",
        "        batch.append(x)\n",
        "    batch = torch.stack(batch, dim=0).to(device)\n",
        "\n",
        "    custom_vit_final.eval()\n",
        "    with autocast(device_type=\"cuda\" if device==\"cuda\" else \"cpu\"):\n",
        "        logits = custom_vit_final(batch)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "\n",
        "    return probs.detach().cpu().numpy()\n",
        "\n",
        "lime_explainer = lime_image.LimeImageExplainer()\n",
        "\n",
        "def lime_segmenter(x):\n",
        "    return slic(x, n_segments=120, compactness=10, sigma=1)\n"
      ],
      "metadata": {
        "id": "MiJ7U3hmGQJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run LIME explanations on images\n",
        "\n",
        "samples_to_show = 4\n",
        "test_n = len(test_loader.dataset)\n",
        "idxs = np.random.choice(range(test_n), size=min(samples_to_show, test_n), replace=False)\n",
        "\n",
        "plt.figure(figsize=(14, 4 * len(idxs)))\n",
        "\n",
        "for row_i, idx in enumerate(idxs, start=1):\n",
        "    img_np, y_true, img_path = get_raw_test_sample(idx)\n",
        "\n",
        "    probs = lime_predict_proba([img_np])[0]\n",
        "    y_pred = int(np.argmax(probs))\n",
        "    conf = float(probs[y_pred])\n",
        "\n",
        "    explanation = lime_explainer.explain_instance(\n",
        "        image=img_np,\n",
        "        classifier_fn=lime_predict_proba,\n",
        "        top_labels=3,\n",
        "        hide_color=0,\n",
        "        num_samples=700,\n",
        "        segmentation_fn=lime_segmenter\n",
        "    )\n",
        "\n",
        "    temp, mask = explanation.get_image_and_mask(\n",
        "        label=y_pred,\n",
        "        positive_only=True,\n",
        "        num_features=12,\n",
        "        hide_rest=False\n",
        "    )\n",
        "\n",
        "    plt.subplot(len(idxs), 3, (row_i-1)*3 + 1)\n",
        "    plt.imshow(img_np)\n",
        "    plt.title(f\"Raw\\nTrue: {classes[y_true]}\\nPred: {classes[y_pred]} ({conf:.2f})\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(len(idxs), 3, (row_i-1)*3 + 2)\n",
        "    plt.imshow(mark_boundaries(temp / 255.0, mask))\n",
        "    plt.title(\"LIME (positive regions)\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    topk = 5\n",
        "    top_idx = np.argsort(probs)[::-1][:topk]\n",
        "    top_probs = probs[top_idx]\n",
        "    top_names = [classes[i] for i in top_idx]\n",
        "\n",
        "    plt.subplot(len(idxs), 3, (row_i-1)*3 + 3)\n",
        "    plt.barh(top_names[::-1], top_probs[::-1])\n",
        "    plt.title(\"Top predictions\")\n",
        "    plt.xlabel(\"Probability\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XeoP6JWkG6xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ulo24N8E80Q"
      },
      "outputs": [],
      "source": [
        "import os, json, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "save_root = \"/content/drive/MyDrive/ml-project2/snake_research_runs\"\n",
        "run_name = time.strftime(\"run_%Y%m%d_%H%M%S\")\n",
        "save_dir = os.path.join(save_root, run_name)\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "print(\"Saving to:\", save_dir)\n",
        "\n",
        "def save_json(obj, path):\n",
        "    with open(path, \"w\") as f:\n",
        "        json.dump(obj, f, indent=2)\n",
        "\n",
        "def save_df(df, path):\n",
        "    df.to_csv(path, index=False)\n",
        "\n",
        "def save_text(text, path):\n",
        "    with open(path, \"w\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "def save_fig(name):\n",
        "    plt.savefig(os.path.join(save_dir, f\"{name}.png\"), dpi=200, bbox_inches=\"tight\")\n",
        "\n",
        "def safe_torch_save(state_dict, name):\n",
        "    torch.save(state_dict, os.path.join(save_dir, name))\n",
        "\n",
        "np.save(os.path.join(save_dir, \"train_idx.npy\"), np.array(train_idx))\n",
        "np.save(os.path.join(save_dir, \"val_idx.npy\"), np.array(val_idx))\n",
        "np.save(os.path.join(save_dir, \"test_idx.npy\"), np.array(test_idx))\n",
        "\n",
        "label_map = {\"class_to_idx\": base_ds.class_to_idx, \"idx_to_class\": {v:k for k,v in base_ds.class_to_idx.items()}}\n",
        "save_json(label_map, os.path.join(save_dir, \"label_map.json\"))\n",
        "\n",
        "if \"hist_mlp_cnn\" in globals():\n",
        "    save_df(pd.DataFrame(hist_mlp_cnn), os.path.join(save_dir, \"hist_mlp_cnn.csv\"))\n",
        "if \"hist_mlp_hybrid\" in globals():\n",
        "    save_df(pd.DataFrame(hist_mlp_hybrid), os.path.join(save_dir, \"hist_mlp_hybrid.csv\"))\n",
        "if \"hist_vit\" in globals():\n",
        "    save_df(pd.DataFrame(hist_vit), os.path.join(save_dir, \"hist_vit.csv\"))\n",
        "if \"hist_final_mlp\" in globals():\n",
        "    save_df(pd.DataFrame(hist_final_mlp), os.path.join(save_dir, \"hist_final_mlp.csv\"))\n",
        "if \"hist_final_vit\" in globals():\n",
        "    save_df(pd.DataFrame(hist_final_vit), os.path.join(save_dir, \"hist_final_vit.csv\"))\n",
        "if \"hist_custom_final\" in globals():\n",
        "    save_df(pd.DataFrame(hist_custom_final), os.path.join(save_dir, \"hist_custom_vit.csv\"))\n",
        "if \"hist_custom_final\" not in globals() and \"hist_custom_final\" in locals():\n",
        "    save_df(pd.DataFrame(hist_custom_final), os.path.join(save_dir, \"hist_custom_vit.csv\"))\n",
        "\n",
        "# Feature MLPs\n",
        "if \"mlp_cnn\" in globals():\n",
        "    safe_torch_save(mlp_cnn.state_dict(), \"mlp_cnnfeat.pth\")\n",
        "if \"mlp_hybrid\" in globals():\n",
        "    safe_torch_save(mlp_hybrid.state_dict(), \"mlp_hybridfeat.pth\")\n",
        "\n",
        "# ViT baseline\n",
        "if \"vit_model\" in globals():\n",
        "    safe_torch_save(vit_model.state_dict(), \"vit_end2end_quick.pth\")\n",
        "if \"vit_final\" in globals():\n",
        "    safe_torch_save(vit_final.state_dict(), \"vit_final_tuned.pth\")\n",
        "\n",
        "# Custom ViT final\n",
        "if \"custom_vit_final\" in globals():\n",
        "    safe_torch_save(custom_vit_final.state_dict(), \"custom_vit_final.pth\")\n",
        "\n",
        "artifacts = {\n",
        "    \"classes\": classes,\n",
        "    \"cfg\": CFG.__dict__,\n",
        "    \"best_model_type\": best_type if \"best_type\" in globals() else None,\n",
        "    \"best_model_tuned_params\": best_params if \"best_params\" in globals() else None,\n",
        "    \"custom_vit_params\": custom_params if \"custom_params\" in globals() else None,\n",
        "}\n",
        "\n",
        "if \"test_m\" in globals():\n",
        "    artifacts[\"custom_vit_test\"] = {\n",
        "        \"acc\": float(test_m.get(\"acc\", -1)),\n",
        "        \"macro_f1\": float(test_m.get(\"f1_macro\", -1)),\n",
        "        \"loss\": float(test_m.get(\"loss\", -1))\n",
        "    }\n",
        "if \"tta_acc\" in globals():\n",
        "    artifacts[\"custom_vit_test_tta\"] = {\"acc\": float(tta_acc), \"macro_f1\": float(tta_f1)}\n",
        "\n",
        "save_json(artifacts, os.path.join(save_dir, \"run_artifacts.json\"))\n",
        "\n",
        "if \"yt_true\" in globals() and \"yt_pred\" in globals():\n",
        "    rep = classification_report(yt_true, yt_pred, target_names=classes, digits=4)\n",
        "    save_text(rep, os.path.join(save_dir, \"classification_report_test.txt\"))\n",
        "\n",
        "    cm = confusion_matrix(yt_true, yt_pred)\n",
        "    np.save(os.path.join(save_dir, \"confusion_matrix_test.npy\"), cm)\n",
        "\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.imshow(cm)\n",
        "    plt.title(\"Confusion Matrix (Test)\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.colorbar()\n",
        "    plt.tight_layout()\n",
        "    save_fig(\"confusion_matrix_test\")\n",
        "    plt.close()\n",
        "\n",
        "if \"Xtr_cnn\" in globals():\n",
        "    np.save(os.path.join(save_dir, \"Xtr_cnn.npy\"), Xtr_cnn)\n",
        "    np.save(os.path.join(save_dir, \"Xva_cnn.npy\"), Xva_cnn)\n",
        "    np.save(os.path.join(save_dir, \"Xte_cnn.npy\"), Xte_cnn)\n",
        "if \"Xtr_h\" in globals():\n",
        "    np.save(os.path.join(save_dir, \"Xtr_hybrid.npy\"), Xtr_h)\n",
        "    np.save(os.path.join(save_dir, \"Xva_hybrid.npy\"), Xva_h)\n",
        "    np.save(os.path.join(save_dir, \"Xte_hybrid.npy\"), Xte_h)\n",
        "\n",
        "print(\"Saved everything into:\", save_dir)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}